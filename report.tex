%FILL THESE IN
\def\mytitle{Computer Graphics \\ Coursework Part 1 - Report}
\def\mykeywords{3D scene, OpenGL, GLSL, shadows, normal mapping, refraction, reflection, Fresnel effect, distortion, instancing, terrain}
\def\myauthor{Dimitar Hristov}
\def\contact{40201757@live.napier.ac.uk}
\def\mymodule{Computer Graphics (SET08116)}
%YOU DON'T NEED TO TOUCH ANYTHING BELOW
\documentclass[10pt, a4paper]{article}
\usepackage[a4paper,outer=1.5cm,inner=1.5cm,top=1.75cm,bottom=1.5cm]{geometry}
\twocolumn
\usepackage{graphicx}
\graphicspath{{./images/}}
%colour our links, remove weird boxes
\usepackage[colorlinks,linkcolor={black},citecolor={blue!80!black},urlcolor={blue!80!black}]{hyperref}
%Stop indentation on new paragraphs
\usepackage[parfill]{parskip}
%% all this is for Arial
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{uarial}
\renewcommand{\familydefault}{\sfdefault}
%Napier logo top right
\usepackage{watermark}
%Lorem Ipusm dolor please don't leave any in you final repot ;)
\usepackage{lipsum}
\usepackage{xcolor}
\usepackage{listings}
%give us the Capital H that we all know and love
\usepackage{float}
%tone down the linespacing after section titles
\usepackage{titlesec}
%Cool maths printing
\usepackage{amsmath}
%PseudoCode
\usepackage{algorithm2e}
\usepackage{hyperref}

\titlespacing{\subsection}{0pt}{\parskip}{-3pt}
\titlespacing{\subsubsection}{0pt}{\parskip}{-\parskip}
\titlespacing{\paragraph}{0pt}{\parskip}{\parskip}
\newcommand{\figuremacro}[5]{
    \begin{figure}[#1]
        \centering
        \includegraphics[width=#5\columnwidth]{#2}
        \caption[#3]{\textbf{#3}#4}
        \label{fig:#2}
    \end{figure}
}

\lstset{
	escapeinside={/*@}{@*/}, language=C++,
	basicstyle=\fontsize{8.5}{12}\selectfont,
	numbers=left,numbersep=2pt,xleftmargin=2pt,frame=tb,
    columns=fullflexible,showstringspaces=false,tabsize=4,
    keepspaces=true,showtabs=false,showspaces=false,
    backgroundcolor=\color{white}, morekeywords={inline,public,
    class,private,protected,struct},captionpos=t,lineskip=-0.4em,
	aboveskip=10pt, extendedchars=true, breaklines=true,
	prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
	keywordstyle=\color[rgb]{0,0,1},
	commentstyle=\color[rgb]{0.133,0.545,0.133},
	stringstyle=\color[rgb]{0.627,0.126,0.941}
}

\thiswatermark{\centering \put(336.5,-38.0){\includegraphics[scale=0.8]{logo}} }
\title{\mytitle}
\author{\myauthor\hspace{1em}\\\contact\\Edinburgh Napier University\hspace{0.5em}-\hspace{0.5em}\mymodule}
\date{}
\hypersetup{pdfauthor=\myauthor,pdftitle=\mytitle,pdfkeywords=\mykeywords}
\sloppy
\begin{document}	
	
	\hyphenchar\font = -1
	
	\maketitle
	\begin{abstract}
		 The aim of this project is to create a realistic 3D scene, rendered in real-time. The project is inspired by the series \textit{Games of Thrones}\cite{dragons} (see \textbf{Figure {\ref{fig:inspiration}}}) and previous years projects found on the games website\cite{gamesWebsite} of Napier University. A wide variety of graphics techniques were used to create the 3D scene, from material shading and post-processing effects to reflective and refractive rippling water. This report covers how the scene was implemented and what future work is considered.
	\end{abstract}
	\\\\
	\textbf{Keywords -- }{\mykeywords}
	\figuremacro{h}{inspiration}{Scenes used as inspiration}{ }{1.0}	
    %START FROM HERE
    
	\section{Introduction}
    \paragraph{Scene parts} The project is meant to be visually intriguing and to demonstrate core understandings of Computer Graphics principles. The 3D scene consists of:   
    \begin{itemize}
    	\item realistic water;
    	\item instancing of 800 dragon eggs made with normal mapping around the island;
    	\item island terrain surrounded by the water;   
    	\item a miniature model of the Earth and the Moon, rotating around it;
    	\item a wall and a spot light demonstrating shadows;
    	\item a model of a dragon next to the Earth, protecting its egg;
    	\item geometry objects moving with hierarchical transformations (one of the dragon eggs and its' protectors);
    	\item a skybox that brings completeness to the scene and also background;	
    \end{itemize}
    
	\paragraph{Graphics effects}The graphics effects implemented in this project include:
	\begin{itemize}
		\item reflective and refractive water with implemented Fresnel effect, depth and distortion;
		\item post-processing effects, including mask, edge detection, sepia, motion blur and wire framing;
		\item multiple light types (directional, spot and point lights);
		\item texturing and normal mapping that give high level of details;
		\item shadows that make the scene more realistic;
	\end{itemize}
    There are two types of cameras implemented within the project: \textit{free and target camera}. The free camera allows the user to go around and explore the 3D scene and the four target cameras show the scene from four static points of view.
    
    Further information about these graphics techniques is given later in the report. \textbf{Figure {\ref{fig:general}}} shows part of these elements and graphics effects.
	\figuremacro{h}{general}{Scene from the project}{ }{1.0}
	
	\section{Related Work}
	Part of the techniques used in the scene can be found in the workbook for the Computer Graphics module - SET08116 at Edinburgh Napier University\cite{book}. In addition to this, for the water effect an online tutorial\cite{onlineTutorial} was followed and adapted for the purposes of this project. Some of the graphics techniques had to be taken further in order to develop the final 3D scene in an optimized way.

	\section{Implementation}
	In order to make the scene alluring, a wide variety of geometry objects were used. These elements are:

	\subsection{Multiple lights}
	There are three types of lighting sources implemented in the project: directional, spot and point lights. Together with the normal maps they give to the geometry objects good realistic views. 
	\\The Phong shading was used throughout the project. It is a graphics technique that calculates light on a per-pixel rather than per-vertex level. It improves upon Gouraud shading and provides a better approximation of the shading of a smooth surface. On \textbf{Figure {\ref{fig:phongAndGouraud}}} is shown the difference between the Gouraud - per-vertex (left) and the Phong - per-pixel (right) shading.
	\figuremacro{h}{phongAndGouraud}{Gouraud and Phong shading}{ }{0.9}	
	\\\textbf{Figure {\ref{fig:phongEquation}}} shows the Phong equation where the light is white, the ambient and diffuse colours are both blue and the specular colour is white. The same properties are applied to the meshes in the scene and used in the fragment shader when calculating the correct colours to be displayed.
	\figuremacro{h}{phongEquation}{Phong shading equation}{ }{1.0}		
	
	\subsection{Texturing and Normal Mapping}
	Texturing is the process by which image data can be applied to geometry objects and models to provide more details. 
    \\Normal mapping is a technique that allows us to calculate the normals on a per-pixel level and gives a high level of detail to the objects. It creates the illusion that a flat mesh has depth on its surface by reacting with the light in the scene. In the project there are normal maps applied to the Earth, the dragon eggs and to the water. See \textbf{Figure {\ref{fig:normalMaps}}} for references.
   	\figuremacro{h}{normalMaps}{Normal maps in the scene}{ }{1.0}	
   	
   	This effect can be achieved with normal map images similar to the one on \textbf{Figure {\ref{fig:bublenormalmap}}}. The RGB values of the texture represents the <x,y,z> components of the normal at this point. In addition to the normal, the bi-normal and the tangent are also required for the transformation matrix that is used to calculate the sampled normal. This normal map is used for the effect achieved on the two dragon eggs on \textbf{Figure {\ref{fig:normalMaps}}}.
	\figuremacro{h}{bublenormalmap}{Normal map}{ }{0.52}	
	   	
	\subsection{Shadows}
	Shadow mapping uses the depth buffer that captures depth information. This allows us to determine if an object is in shadow based on the light hitting the mesh. \textbf{Figure {\ref{fig:shadowExpl}}} shows an example of how the depth buffer is working to calculate which mesh is lit and which one is in shadow. 
	\figuremacro{h}{shadowExpl}{Depth buffer}{ }{1.0}	
	\\In the scene the shadows are created with one spot light which is casting light on meshes in front of the wall. In order to create more realistic shadows, the projection matrix that is used is with a wider field of view. The normal angle for the FoV is $\pi/4$ and for the shadows it is changed to $\pi/2$. The reason for this is because the camera has a narrower FoV than the cone of the spot light and this may result in clipping. \textbf{Figure {\ref{fig:shadowStick}}} demonstrates the shadow casting in the project. 
	\figuremacro{h}{shadowStick}{Shadow}{ }{0.9}
	
	Apart from creating shadows the depth buffer is also used to determine the depth of the water. By using this we can make the water more transparent in the shallow areas and more murky in the deep areas. More on this can be found in the water section.
	
	\subsection{Moving objects}
	For the implementation of the moving objects the $\sin$ and $\cos$ functions were used. By using their main property (shown on \textbf{Figure {\ref{fig:sincos}}}) the position of the meshes are changed in a predefined range.	
	\figuremacro{h}{sincos}{$\sin$ and $\cos$ functions}{ }{0.9}
	\subsection{Hierarchical Transformations}
	Hierarchical transformations is a cheap way of inheriting all the scale, rotation and translation of one mesh by another, all with just one multiplication. In this project the egg protectors are an example of a hierarchical transformations. In order to achieve the final effect the model matrix of the current torus is calculated from the model matrices of the bigger toruses. \textbf{Figure {\ref{fig:hierarchicalTransformations}}} shows the result of this graphics effect in the project.
	\\\\
	$[ModelMatrix]~=~[Translation]~*~[Rotation]~*~[Scale]$~
	\figuremacro{h}{hierarchicalTransformations}{Hierarchical Transformations}{ }{0.8}
	\subsection{Skybox}
	The skybox is a great graphics effect that brings completeness and background to the 3D scene. The effect is achieved with a cube that has a texture applied to its inner sides and the internal parts of the cube are rendered rather than the external parts by disabling the cull face. Cube map similar to the one on \textbf{Figure {\ref{fig:skybox}}} can be used for the inner parts of the cube.
	\figuremacro{h}{skybox}{Cube map used in the project}{ }{0.9}	
	
	The cube map is also used for the reflection part of the water. There we sample the cube map based on the view direction and the surface normal. More on this can be found in the water section. 
	\subsection{Terrain}
	The terrain is a geometry object that makes the scene even more realistic. It is generated using a height map. \textbf{Figure {\ref{fig:heightmap}}} shows an example of a height map. A height map is a texture that contains height data where the pixel colour represents the y-component of the vertex position. The height map from \textbf{Figure{\ref{fig:heightmap}}} is used in this project. The dark and white pixels represent the low and high parts of the scene, respectively. 
	\figuremacro{h}{heightmap}{Height map}{ }{0.8}
	
	A crucial part of the terrain is multi-texturing and generating texture weights. These two features make the terrain more natural. The texture weights are generated based on the height of the terrain and later used in the shaders to blend between the textures. \textbf{Figure {\ref{fig:multiTexturing}}} shows an example of multi-texturing terrain from the project.
	\figuremacro{h}{multiTexturing}{Multi-texturing terrain. Sand-Grass-Rocks}{ }{0.8}
	\subsection{Water}
	The terrain representing an island is surrounded by water. A wide variety of effects are used on the water to make it more realistic:
	\subsubsection{Reflection}
	The reflective part of the water is implemented by sampling a cubemap texture that is used as an environment map. The main difference between a normal 2D texture and a cubemap texture is the way it is sampled. The latter is sampled with 3D directional vector that points in the direction of the cubemap texture that is to be sampled. \textbf{Figure {\ref{fig:cubemapReflection}}} shows an example of cubemap reflection.
	\figuremacro{h}{cubemapReflection}{Reflection with cube map}{ }{1.0}

	In the project, the reflective object is a plane, hence all normals are pointing in the same direction - upwards and the used environment map is the skybox. \textbf{Figure {\ref{fig:reflectedSun}}} shows the reflection of the sun and the clouds on the water.
	\figuremacro{h}{reflectedSun}{Reflection of the sun and the clouds}{ }{0.9}
	\subsubsection{Refraction}
	The refraction effect is achieved by rendering the scene to a frame buffer and using the texture later when defining the colour of the water. However, rendering the whole scene twice would be extremely inefficient. For this reason, clipping plane is used and only the refracted parts of the scene are rendered the second time. Clipping planes allows us to specify a 3D plane in the world and all the geometry objects that have negative distance (they are outside this plane) are not rendered. The way to specify if something is inside the clipping plane is by using the dot product of the vertex and the plane.  See \textbf{Figure {\ref{fig:clippingPlane}}} for references. 
	\figuremacro{h}{clippingPlane}{Distance to clipping plane}{ }{1.0}
	
	In this case, the level of the clipping plane is the level of the water. \textbf{Figure {\ref{fig:refraction}}} shows the refracted terrain under the water.
	\figuremacro{h}{refraction}{Refraction - terrain under the water}{ }{0.9}
	\subsubsection{Distortion effect}
	The Distortion effect is achieved with a DuDv map (\textbf{Figure {\ref{fig:DuDvMap}}}) which makes the water looks like it is rippling. The DuDv map is just a 2D texture with red and green lobes on it which can be represented as a 2D vector.
	\figuremacro{h}{DuDvMap}{DuDv map}{ }{0.7}
	
	The way it is working is by sampling the DuDv map and then distorting the reflection and refraction textures by adding the sampled offsets to their texture coordinates. To increase the level of detail a matching to the DuDv map, normal map texture is used. It is sampled with the distorted texture coordinates and it makes the water more shiny. The result is shown on \textbf{Figure {\ref{fig:distortion}}}. It makes the water more natural by adding this level of detail.
	\figuremacro{h}{distortion}{Distorted refraction texture}{ }{1.0}
	
	\subsubsection{The Fresnel effect}
	After the reflection and refraction textures are captured and distorted, they are blended based on the Fresnel effect. This determines how much of each texture must be seen based on the viewing angle. When we look straight down into the water it appears to be fairly transparent and when we look across the water surface at a low angle it looks more reflective. The viewing angle is determined from the dot product of the surface normal and the view direction of the camera. The more these two vectors point in the same direction, the more transparent the water is. See \textbf{Figure {\ref{fig:fresnelDrawing}}} for reference.
	\figuremacro{h}{fresnelDrawing}{Viewing angle used for the Fresnel effect}{ }{1.0}
	
	\textbf{Figure {\ref{fig:fresnelEffect}}} shows an example of the Fresnel effect in the scene. The area of water that is closer to the camera, seems to be more transparent. The area of water that is further away from the camera is much more reflective due to the large angle.
	\figuremacro{h}{fresnelEffect}{Fresnel effect}{ }{0.9}
	\subsubsection{The depth effect}
	The depth effect makes the water seem more transparent around the shallow areas and more murky around the deeper areas. For this effect, the depth buffer of the refraction part of the scene and the build-in OpenGL variable - \textit{gl\_FragCoord} are used. The depth buffer returns the distance of the nearest object under the water to the camera. And the \textit{gl\_FragCoord} returns the window coordinate of the current fragment. Then we subtract one distance from the other and the result is the depth of the water from the perspective of the camera (the amount of water between the camera and the refracted object). See \textbf{Figure {\ref{fig:refractionDistance}}} for reference.
	\figuremacro{h}{refractionDistance}{Water depth}{ }{1.0}
	
	The tricky part is to get linear depth (the true z value) from the depth buffer by using the near- and far-clip planes. The results of these calculation are shows on \textbf{Figure {\ref{fig:depthBuffer}}}.
	\figuremacro{h}{depthBuffer}{Water depth}{ }{1.0}
	
	The whiter a pixel is, the further away from the camera it is. The shallow areas of the water are shown in black. In order to achieve the final result, alpha blending is used. \textbf{Figure {\ref{fig:refraction}}} shows an example of this effect from the scene.
	\subsection{Post-processing effects}
	Post-processing is a technique where a frame is captured in a texture, different effects are applied to the colours of the pixels and it is rendered back to the screen.
	\subsubsection{Mask}
	This is a multi-texturing technique. This effect is achieved with a back and white mask similar to the one on FIGURE. In the fragment shader both the mask and the texture from the frame buffer are sampled and there colours are multiplied together to get the final colour. In this way only the white parts of the mask are visible in the final image. FIGURE shows an example from the project. The effect of zooming in is achieved by changing the FoV angle in the projection of the camera.
	\subsubsection{Edge detection}
	Edge detection is a post-processing effect where only the edges of the geometry objects are visible. For every pixel it is determined if it is part of the edge based on the colours of the pixels around it. Suppose there are 9 pixels as 
	shown on \textbf{Figure {\ref{fig:edgeDetectionMatrix}}}. 
	\figuremacro{h}{edgeDetectionMatrix}{Multi-texturing terrain. Sand-Grass-Rocks}{ }{0.8}
	\\After applying the edge detection filter, the intensity of pixel $I_{x}$ is determined from the formula: \\\\
	$I_{x}~=\dfrac{~|I_{1}~-~I_{7}|~+~|I_{5}~-~I_{3}|~+~|I_{0}~-~I_{8}|~+~|I_{2}~-~I_{6}|}{4}$~
	\\\\ In order to be able to calculate pixel intensity we need to find out intensity differences between neighboring pixels and average them. Then the average value is checked against a threshold. If the intensity is greater than the threshold that mean that there is hight contrast and hence this is an edge. FIGURE shows the edge detection effect in the project.
	\subsubsection{Sepia}
	The Sepia post-processing effect is easily achievable by first applying the gray scale effect. In order to do that we need to work out the intensity of an individual pixel. This can be done with the equation: $i = f \cdot c$, where \textit{c} is the vector representing the colour value and \textit{f} = (0.299, 0.587, 0.184), which is the gray scale intensity value and gives different weight to the red, green and blue colours. After this the Sepia effect is achieved by adding the colour (0.314, 0.169, -0.090) to the outgoing gray scale. FIGURE shows an example of this effect from the scene.
	\subsubsection{Motion blur}
	Motion Blur is an effect that uses two frame buffers and the textures stored in them to create the required blurring. The Motion Blur can be achieved with the standard multi-texturing approach by blending the current render with the previous one. FIGURE shows an example of Motion Blur.
	\subsection{Wire framing}
	Wire framing is a nice effect that shows the primitive geometry that structures all models and more complex geometry objects. FIGURE shows an example of this effect in the project.
	\section{Optimization}
	The scene in this project consists of quite a lot of geometry objects and additional effects. Doing optimization is crucial in this case in order to improve the performance of the GPU.
	\subsection{Instancing}
	One of the used optimization technique is Instancing. Instancing  allows us to draw many geometry objects at once with a single render call, saving us all the CPU -> GPU communications each time we need to render the object. With instancing this is done only once and it avoids the performance bottleneck on the relatively slow CPU to GPU bus. All the required data is sent to the GPU only once and then the CPU renders all the instances without having to continually communicate with the CPU. This method of drawing is really efficient for rendering a lot of models where most of these models contain the same set of vertex data but with different world transformations. For example, grass or rocks on the seabed. In this project, instancing is used to render 800 dragon eggs around the island under the water. See FIGURE for references.
	\figuremacro{h}{instancing}{800 Dragon Eggs rendered with Instancing}{ }{1.0}
	\section{Future Work}
	The initial plan for the 3D scene was to have terrain as well, however, because of the lack of time it was not possible to create it. This is something which is definitely considered  for future development. In addition to this, there will be post-processing effects such as: Blurring, Motion Blur, Masking, Greyscale and fully reflective objects. 
	\section{Conclusion}
	At this stage the scene was successfully finished with all the required techniques and effects. By undertaking the future work, the scene will became even more interesting and visually appealing.	
\bibliographystyle{ieeetr}
\bibliography{references}
		
\end{document}
